"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[967],{1286:function(t,e,n){n.d(e,{Iy:function(){return SymbolicTensor},NB:function(){return Node},Zg:function(){return InputSpec},hA:function(){return function getSourceInputs(t,e,n){if((null==e||null!=n&&n>0)&&(e=t.sourceLayer,n=t.nodeIndex),0===e.inboundNodes.length)return[t];{let t=e.inboundNodes[n];if(0===t.inboundLayers.length)return t.inputTensors;{let e=[];for(let n=0;n<t.inboundLayers.length;n++){let i=t.inputTensors[n],s=t.inboundLayers[n],h=t.nodeIndices[n],a=getSourceInputs(i,s,h);for(let t of a)-1===e.indexOf(t)&&e.push(t)}return e}}}},mh:function(){return Layer}});var i=n(8130),s=n(5470),h=n(5351),a=n(8791),o=n(5136),r=n(4543),l=n(6567),u=n(607),p=n(6883);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */let InputSpec=class InputSpec{constructor(t){this.dtype=t.dtype,this.shape=t.shape,null!=t.shape?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}};let SymbolicTensor=class SymbolicTensor{constructor(t,e,n,i,a,o,r){this.dtype=t,this.shape=e,this.sourceLayer=n,this.inputs=i,this.callArgs=a,this.outputTensorIndex=r,this.id=(0,s.L)(),null!=o&&(this.originalName=(0,h.MU)(o),this.name=(0,h.w8)(this.originalName)),this.rank=e.length}};let d=0;let Node=class Node{constructor(t,e){for(let n of(this.callArgs=e,this.id=d++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes,t.inboundLayers))null!=n&&n.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){let t=[];for(let e of this.inboundLayers)null!=e?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}};let f=0;let Layer=class Layer extends i.m7h.Serializable{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=f++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){let t=this.getClassName();e=r.D1(t)+"_"+(0,s.s)(t)}if(this.name=e,this.trainable_=null==t.trainable||t.trainable,null!=t.inputShape||null!=t.batchInputShape){let e;if(null!=t.batchInputShape)e=t.batchInputShape;else if(null!=t.inputShape){let n=null;null!=t.batchSize&&(n=t.batchSize),e=[n].concat(t.inputShape)}this.batchInputShape=e;let n=t.dtype;null==n&&(n=t.inputDType),null==n&&(n="float32"),this.dtype=n}null!=t.weights?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(0===this.inboundNodes.length)throw new a.LH(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new a.nu(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return r.Bq(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return r.Bq(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new a.j1(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new a.j1(`Layer ${this.name} is not connected, no input to return.`);return r.Bq(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new a.j1(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new a.j1(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return r.Bq(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(t=>t())}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach(e=>e.trainable=t),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(t=>t.trainable):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(t=>!t.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){let e=r.zZ(t);if(null==this.inputSpec||0===this.inputSpec.length)return;let n=r.zZ(this.inputSpec);if(e.length!==n.length)throw new a.nu(`Layer ${this.name} expects ${n.length} inputs, but it received ${e.length} input tensors. Input received: ${t}`);for(let t=0;t<e.length;t++){let i=e[t],s=n[t];if(null==s)continue;let h=i.rank;if(null!=s.ndim&&h!==s.ndim)throw new a.nu(`Input ${t} is incompatible with layer ${this.name}: expected ndim=${s.ndim}, found ndim=${h}`);if(null!=s.maxNDim&&h>s.maxNDim)throw new a.nu(`Input ${t} is incompatible with layer ${this.name}: expected max_ndim=${s.maxNDim}, found ndim=${h}`);if(null!=s.minNDim&&h<s.minNDim)throw new a.nu(`Input ${t} is incompatible with layer ${this.name}: expected min_ndim=${s.minNDim}, found ndim=${h}.`);if(null!=s.dtype&&i.dtype!==s.dtype)throw new a.nu(`Input ${t} is incompatible with layer ${this.name} : expected dtype=${s.dtype}, found dtype=${i.dtype}.`);if(s.axes){let e=i.shape;for(let n in s.axes){let i=Number(n),h=s.axes[n],o=i>=0?e[i]:e[e.length+i];if(null!=h&&-1===[h,null].indexOf(o))throw new a.nu(`Input ${t} is incompatible with layer ${this.name}: expected axis ${i} of input shape to have value ${h} but got shape ${e}.`)}}if(null!=s.shape)for(let e=0;e<s.shape.length;++e){let n=s.shape[e],h=i.shape[e];if(null!=n&&null!=h&&n!==h)throw new a.nu(`Input ${t} is incompatible with layer ${this.name}: expected shape=${s.shape}, found shape=${i.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){null!=this._callHook&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();let n=r.zZ(t),i=function(t){let e=!0;for(let n of r.zZ(t))if(!(n instanceof SymbolicTensor)){e=!1;break}return e}(t),s=function(t){let e=!0;for(let n of r.zZ(t))if(n instanceof SymbolicTensor){e=!1;break}return e}(t);if(i===s)throw new a.nu("Arguments to apply() must be all SymbolicTensors or all Tensors");return(0,h.f4)(this.name,()=>{if(!this.built){this.assertInputCompatibility(t);let e=[];for(let n of r.zZ(t))e.push(n.shape);this.build(r.Bq(e)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&s&&(this._refCount=1)}if(this.assertInputCompatibility(t),s){let i=this.call(t,e);this.supportsMasking&&this.setMaskMetadata(t,i);let s=r.zZ(i),h=[];for(let t of s)-1!==n.indexOf(t)&&(t=t.clone()),h.push(t);if(i=r.Bq(h),null!=this.activityRegularizer)throw new a.nj("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return i}{let n;let i=function(t){t=r.zZ(t);let e=[];for(let n of t)e.push(n.shape);return r.Bq(e)}(t),s=this.computeOutputShape(i),h="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(t)?i[0]:i),n=null!=s&&s.length>0&&Array.isArray(s[0])?s.map((n,i)=>new SymbolicTensor(h,n,this,r.zZ(t),e,this.name,i)):new SymbolicTensor(h,s,this,r.zZ(t),e,this.name),this.addInboundNode(t,n,null,null,i,s,e),this._refCount++,null!=this.activityRegularizer)throw new a.nj("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return n}})}warnOnIncompatibleInputShape(t){if(null!=this.batchInputShape){if(t.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let e=!1;this.batchInputShape.forEach((n,i)=>{null!=n&&null!=t[i]&&t[i]!==n&&(e=!0)}),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new a.j1(`The layer ${this.name} has never been called and thus has no defined output shape.`);let t=[];for(let e of this.inboundNodes){let n=JSON.stringify(e.outputShapes);-1===t.indexOf(n)&&t.push(n)}if(1===t.length){let t=this.inboundNodes[0].outputShapes;return Array.isArray(t)&&Array.isArray(t[0])&&1===t.length?t[0]:t}throw new a.j1(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new a.LH(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return u.t(this.weights)}build(t){this.built=!0}getWeights(t=!1){return(0,p.FQ)(t?this.trainableWeights:this.weights)}setWeights(t){(0,i.lub)(()=>{let e=this.weights;if(e.length!==t.length)throw new a.nu(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(0===e.length)return;let n=[],s=(0,p.FQ)(e);for(let h=0;h<s.length;++h){let o=s[h],r=e[h],l=t[h];if(!i.D5U.arraysEqual(o.shape,l.shape))throw new a.nu(`Layer weight shape ${o.shape} not compatible with provided weight shape ${l.shape}`);n.push([r,l])}(0,p.zb)(n)})}addWeight(t,e,n,i,s,h,r,l){if(-1!==this._addedWeightNames.indexOf(t))throw new a.nu(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(i=null!=l?l():(0,o.L5)("zeros"));let u=i.apply(e,n),d=new p.fU(u,n,t,h,r);return u.dispose(),null!=s&&this.addLoss(()=>s.apply(d.read())),null==h&&(h=!0),h?this._trainableWeights.push(d):this._nonTrainableWeights.push(d),d}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){null==t||Array.isArray(t)&&0===t.length||(t=r.zZ(t),void 0!==this._losses&&null!==this._losses&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(null!=e){if(Array.isArray(e))e.forEach(t=>{if(null!=t)throw TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)});else throw TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)}return null}return e}setMaskMetadata(t,e,n){if(!this.supportsMasking)return;let i=this.computeMask(t,n);if(e instanceof Array&&i instanceof Array){if(e.length!==i.length)throw Error(`${this.name} outputs ${e.length} tensors but ${i.length} masks for those tensors`);for(let t=0;t<e.length;t++)e[t].kerasMask=i[t]}else if(i instanceof Array)throw Error(`{this.name} outputs a single tensor but ${i.length} masks`);else if(e instanceof Array)throw Error(`{this.name} outputs ${e.length} tensors but only one mask`);else e.kerasMask=i}addInboundNode(t,e,n,i,s,h,a=null){let o=r.zZ(t);e=r.zZ(e),n=r.zZ(n),i=r.zZ(i),s=l.x6(s),h=l.x6(h);let u=[],p=[],d=[];for(let t of o)u.push(t.sourceLayer),p.push(t.nodeIndex),d.push(t.tensorIndex);new Node({outboundLayer:this,inboundLayers:u,nodeIndices:p,tensorIndices:d,inputTensors:o,outputTensors:e,inputMasks:n,outputMasks:i,inputShapes:s,outputShapes:h},a);for(let t=0;t<e.length;t++)e[t].sourceLayer=this,e[t].nodeIndex=this.inboundNodes.length-1,e[t].tensorIndex=t}getConfig(){let t={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(t.batchInputShape=this.batchInputShape),null!=this.dtype&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach(t=>t.dispose()),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return 0==--this._refCount&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}}}]);