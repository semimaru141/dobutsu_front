"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[399],{6282:function(i,e,t){t.d(e,{aP:function(){return preprocessConv2DInput},fN:function(){return preprocessConv3DInput},nx:function(){return BaseConv}});var n=t(8130),s=t(8151),r=t(2406),a=t(7676),l=t(5351),o=t(2944),h=t(1286),p=t(8791),d=t(5136),u=t(3135),c=t(5694),g=t(4543),f=t(6567);/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function preprocessConv2DInput(i,e){return(0,n.lub)(()=>((0,l.cj)(e),"channelsFirst"===e)?n.p4s(i,[0,2,3,1]):i)}function preprocessConv3DInput(i,e){return(0,n.lub)(()=>((0,l.cj)(e),"channelsFirst"===e)?n.p4s(i,[0,2,3,4,1]):i)}function conv2dWithBiasActivation(i,e,t,s=[1,1],a="valid",o,h,d=null){return(0,n.lub)(()=>{if(null==o&&(o=(0,r.rf)()),(0,l.cj)(o),3!==i.rank&&4!==i.rank)throw new p.nu(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${i.rank}.`);if(3!==e.rank&&4!==e.rank)throw new p.nu(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${i.rank}.`);let u=preprocessConv2DInput(i,o);if("causal"===a)throw new p.nj("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return u=n.imm.conv2d({x:u,filter:e,strides:s,pad:"same"===a?"same":"valid",dilations:h,dataFormat:"NHWC",bias:t,activation:d}),"channelsFirst"===o&&(u=n.p4s(u,[0,3,1,2])),u})}let BaseConv=class BaseConv extends h.mh{constructor(i,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",BaseConv.verifyArgs(e),this.rank=i,g.iQ(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new p.nj(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=(0,c.AF)(e.kernelSize,i,"kernelSize"),this.strides=(0,c.AF)(null==e.strides?1:e.strides,i,"strides"),this.padding=null==e.padding?"valid":e.padding,(0,l.zb)(this.padding),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,(0,l.cj)(this.dataFormat),this.activation=(0,s.aI)(e.activation),this.useBias=null==e.useBias||e.useBias,this.biasInitializer=(0,d.L5)(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=(0,o.Ad)(e.biasConstraint),this.biasRegularizer=(0,u.EC)(e.biasRegularizer),this.activityRegularizer=(0,u.EC)(e.activityRegularizer),this.dilationRate=(0,c.AF)(null==e.dilationRate?1:e.dilationRate,i,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new p.nu(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new p.nu(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new p.nu(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}}static verifyArgs(i){if(g.hu("kernelSize"in i,"required key 'kernelSize' not in config"),"number"!=typeof i.kernelSize&&!g.Mx(i.kernelSize,"number",1,3))throw new p.nu(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(i.kernelSize)}.`)}getConfig(){let i={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:(0,s.GD)(this.activation),useBias:this.useBias,biasInitializer:(0,d.Cx)(this.biasInitializer),biasRegularizer:(0,u.SG)(this.biasRegularizer),activityRegularizer:(0,u.SG)(this.activityRegularizer),biasConstraint:(0,o.xF)(this.biasConstraint)},e=super.getConfig();return Object.assign(i,e),i}};let Conv=class Conv extends BaseConv{constructor(i,e){super(i,e),this.kernel=null,Conv.verifyArgs(e),this.filters=e.filters,g.iQ(this.filters,"filters"),this.kernelInitializer=(0,d.L5)(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=(0,o.Ad)(e.kernelConstraint),this.kernelRegularizer=(0,u.EC)(e.kernelRegularizer)}build(i){i=(0,f.Wf)(i);let e="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[e])throw new p.nu(`The channel dimension of the input should be defined. Found ${i[e]}`);let t=i[e],n=this.kernelSize.concat([t,this.filters]);this.kernel=this.addWeight("kernel",n,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:t}}],this.built=!0}call(i,e){return(0,n.lub)(()=>{let e;i=(0,f.nQ)(i);let t=null==this.bias?null:this.bias.read(),s=g.WT(this.activation.getClassName());if(null!=s&&2===this.rank)e=conv2dWithBiasActivation(i,this.kernel.read(),t,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)e=function(i,e,t,s=1,o="valid",h,d=1){return(0,n.lub)(()=>{if(null==h&&(h=(0,r.rf)()),(0,l.cj)(h),3!==i.shape.length)throw new p.nu(`The input of a conv1dWithBias operation should be 3, but is ${i.shape.length} instead.`);if(3!==e.shape.length)throw new p.nu(`The kernel for a conv1dWithBias operation should be 3, but is ${e.shape.length} instead`);if(null!=t&&1!==t.shape.length)throw new p.nu(`The bias for a conv1dWithBias operation should be 1, but is ${e.shape.length} instead`);if("channelsFirst"===h&&(i=n.p4s(i,[0,2,1])),"causal"===o)throw new p.nj("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let u=n.PAt(i,e,s,"same"===o?"same":"valid","NWC",d);return null!=t&&(u=a.a2(u,t)),u})}(i,this.kernel.read(),t,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=conv2dWithBiasActivation(i,this.kernel.read(),t,this.strides,this.padding,this.dataFormat,this.dilationRate);else if(3===this.rank)e=function(i,e,t,s=[1,1,1],o="valid",h,d){return(0,n.lub)(()=>{if(null==h&&(h=(0,r.rf)()),(0,l.cj)(h),4!==i.rank&&5!==i.rank)throw new p.nu(`conv3dWithBias expects input to be of rank 4 or 5, but received ${i.rank}.`);if(4!==e.rank&&5!==e.rank)throw new p.nu(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${i.rank}.`);let u=preprocessConv3DInput(i,h);if("causal"===o)throw new p.nj("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return u=n.pdZ(u,e,s,"same"===o?"same":"valid","NDHWC",d),null!=t&&(u=a.a2(u,t)),"channelsFirst"===h&&(u=n.p4s(u,[0,4,1,2,3])),u})}(i,this.kernel.read(),t,this.strides,this.padding,this.dataFormat,this.dilationRate);else throw new p.nj("convolutions greater than 3D are not implemented yet.");null!=this.activation&&(e=this.activation.apply(e))}return e})}computeOutputShape(i){i=(0,f.Wf)(i);let e=[],t="channelsLast"===this.dataFormat?i.slice(1,i.length-1):i.slice(2);for(let i=0;i<t.length;++i){let n=(0,c.kt)(t[i],this.kernelSize[i],this.padding,this.strides[i],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[i]);e.push(n)}let n=[i[0]];return"channelsLast"===this.dataFormat?(n=n.concat(e)).push(this.filters):(n.push(this.filters),n=n.concat(e)),n}getConfig(){let i={filters:this.filters,kernelInitializer:(0,d.Cx)(this.kernelInitializer),kernelRegularizer:(0,u.SG)(this.kernelRegularizer),kernelConstraint:(0,o.xF)(this.kernelConstraint)},e=super.getConfig();return Object.assign(i,e),i}static verifyArgs(i){if(!("filters"in i)||"number"!=typeof i.filters||i.filters<1)throw new p.nu(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(i.filters)}`)}};let Conv2D=class Conv2D extends Conv{constructor(i){super(2,i),Conv2D.verifyArgs(i)}getConfig(){let i=super.getConfig();return delete i.rank,i}static verifyArgs(i){if("number"!=typeof i.kernelSize&&!g.Mx(i.kernelSize,"number",1,2))throw new p.nu(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(i.kernelSize)}.`)}};Conv2D.className="Conv2D",n.m7h.registerClass(Conv2D);let Conv3D=class Conv3D extends Conv{constructor(i){super(3,i),Conv3D.verifyArgs(i)}getConfig(){let i=super.getConfig();return delete i.rank,i}static verifyArgs(i){if("number"!=typeof i.kernelSize&&!(Array.isArray(i.kernelSize)&&(1===i.kernelSize.length||3===i.kernelSize.length)))throw new p.nu(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(i.kernelSize)}.`)}};Conv3D.className="Conv3D",n.m7h.registerClass(Conv3D);let Conv2DTranspose=class Conv2DTranspose extends Conv2D{constructor(i){if(super(i),this.inputSpec=[new h.Zg({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new p.nu(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(i){if(4!==(i=(0,f.Wf)(i)).length)throw new p.nu("Input should have rank 4; Received input shape: "+JSON.stringify(i));let e="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[e])throw new p.nu("The channel dimension of the inputs should be defined. Found `None`.");let t=i[e],n=this.kernelSize.concat([this.filters,t]);this.kernel=this.addWeight("kernel",n,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new h.Zg({ndim:4,axes:{[e]:t}})],this.built=!0}call(i,e){return n.lub(()=>{let e,t,s=(0,f.nQ)(i);if(4!==s.shape.length)throw new p.nu(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);let r=s.shape,l=r[0];"channelsFirst"===this.dataFormat?(e=2,t=3):(e=1,t=2);let o=r[e],h=r[t],d=this.kernelSize[0],u=this.kernelSize[1],g=this.strides[0],m=this.strides[1],b=(0,c.$U)(o,g,d,this.padding),v=(0,c.$U)(h,m,u,this.padding),k=[l,b,v,this.filters];"channelsLast"!==this.dataFormat&&(s=n.p4s(s,[0,2,3,1]));let C=n.bc(s,this.kernel.read(),k,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(C=n.p4s(C,[0,3,1,2])),null!=this.bias&&(C=a.a2(C,this.bias.read(),this.dataFormat)),null!=this.activation&&(C=this.activation.apply(C)),C})}computeOutputShape(i){let e,t,n;i=(0,f.Wf)(i);let s=i.slice();"channelsFirst"===this.dataFormat?(e=1,t=2,n=3):(e=3,t=1,n=2);let r=this.kernelSize[0],a=this.kernelSize[1],l=this.strides[0],o=this.strides[1];return s[e]=this.filters,s[t]=(0,c.$U)(s[t],l,r,this.padding),s[n]=(0,c.$U)(s[n],o,a,this.padding),s}getConfig(){let i=super.getConfig();return delete i.dilationRate,i}};Conv2DTranspose.className="Conv2DTranspose",n.m7h.registerClass(Conv2DTranspose);let Conv3DTranspose=class Conv3DTranspose extends Conv3D{constructor(i){if(super(i),this.inputSpec=[new h.Zg({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new p.nu(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(i){if(5!==(i=(0,f.Wf)(i)).length)throw new p.nu("Input should have rank 5; Received input shape: "+JSON.stringify(i));let e="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[e])throw new p.nu("The channel dimension of the inputs should be defined. Found `None`.");let t=i[e],n=this.kernelSize.concat([this.filters,t]);this.kernel=this.addWeight("kernel",n,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new h.Zg({ndim:5,axes:{[e]:t}})],this.built=!0}call(i,e){return n.lub(()=>{let e,t,s,r=(0,f.nQ)(i);if(5!==r.shape.length)throw new p.nu(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${r.shape.length}`);let l=r.shape,o=l[0];"channelsFirst"===this.dataFormat?(s=2,e=3,t=4):(s=1,e=2,t=3);let h=l[s],d=l[e],u=l[t],g=this.kernelSize[0],m=this.kernelSize[1],b=this.kernelSize[2],v=this.strides[0],k=this.strides[1],C=this.strides[2],w=(0,c.$U)(h,v,g,this.padding),z=(0,c.$U)(d,k,m,this.padding),S=(0,c.$U)(u,C,b,this.padding),I=[o,w,z,S,this.filters];"channelsLast"!==this.dataFormat&&(r=n.p4s(r,[0,2,3,4,1]));let F=n.$QV(r,this.kernel.read(),I,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(F=n.p4s(F,[0,4,1,2,3])),null!==this.bias&&(F=a.a2(F,this.bias.read(),this.dataFormat)),null!==this.activation&&(F=this.activation.apply(F)),F})}computeOutputShape(i){let e,t,n,s;i=(0,f.Wf)(i);let r=i.slice();"channelsFirst"===this.dataFormat?(e=1,t=2,n=3,s=4):(e=4,t=1,n=2,s=3);let a=this.kernelSize[0],l=this.kernelSize[1],o=this.kernelSize[2],h=this.strides[0],p=this.strides[1],d=this.strides[2];return r[e]=this.filters,r[t]=(0,c.$U)(r[t],h,a,this.padding),r[n]=(0,c.$U)(r[n],p,l,this.padding),r[s]=(0,c.$U)(r[s],d,o,this.padding),r}getConfig(){let i=super.getConfig();return delete i.dilationRate,i}};Conv3DTranspose.className="Conv3DTranspose",n.m7h.registerClass(Conv3DTranspose);let SeparableConv=class SeparableConv extends Conv{constructor(i,e){if(super(i,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==e.filters)throw new p.nu("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=e.kernelInitializer||null!=e.kernelRegularizer||null!=e.kernelConstraint)throw new p.nu("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=e.padding&&"same"!==e.padding&&"valid"!==e.padding)throw new p.nu(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=(0,d.L5)(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=(0,u.EC)(e.depthwiseRegularizer),this.depthwiseConstraint=(0,o.Ad)(e.depthwiseConstraint),this.pointwiseInitializer=(0,d.L5)(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=(0,u.EC)(e.pointwiseRegularizer),this.pointwiseConstraint=(0,o.Ad)(e.pointwiseConstraint)}build(i){if((i=(0,f.Wf)(i)).length<this.rank+2)throw new p.nu(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(i)}`);let e="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[e]||i[e]<0)throw new p.nu(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(i[e])}`);let t=i[e],n=this.kernelSize.concat([t,this.depthMultiplier]),s=[];for(let i=0;i<this.rank;++i)s.push(1);s.push(t*this.depthMultiplier,this.filters),this.depthwiseKernel=this.addWeight("depthwise_kernel",n,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",s,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,!0,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.inputSpec=[new h.Zg({ndim:this.rank+2,axes:{[e]:t}})],this.built=!0}call(i,e){return(0,n.lub)(()=>{let e;if(i=(0,f.nQ)(i),1===this.rank)throw new p.nj("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(i=n.p4s(i,[0,2,3,1])),e=n.U_I(i,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(e=a.a2(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),"channelsFirst"===this.dataFormat&&(e=n.p4s(e,[0,3,1,2])),e})}getConfig(){let i=super.getConfig();return delete i.rank,delete i.kernelInitializer,delete i.kernelRegularizer,delete i.kernelConstraint,i.depthwiseInitializer=(0,d.Cx)(this.depthwiseInitializer),i.pointwiseInitializer=(0,d.Cx)(this.pointwiseInitializer),i.depthwiseRegularizer=(0,u.SG)(this.depthwiseRegularizer),i.pointwiseRegularizer=(0,u.SG)(this.pointwiseRegularizer),i.depthwiseConstraint=(0,o.xF)(this.depthwiseConstraint),i.pointwiseConstraint=(0,o.xF)(this.pointwiseConstraint),i}};SeparableConv.className="SeparableConv";let SeparableConv2D=class SeparableConv2D extends SeparableConv{constructor(i){super(2,i)}};SeparableConv2D.className="SeparableConv2D",n.m7h.registerClass(SeparableConv2D);let Conv1D=class Conv1D extends Conv{constructor(i){super(1,i),Conv1D.verifyArgs(i),this.inputSpec=[{ndim:3}]}getConfig(){let i=super.getConfig();return delete i.rank,delete i.dataFormat,i}static verifyArgs(i){if("number"!=typeof i.kernelSize&&!g.Mx(i.kernelSize,"number",1,1))throw new p.nu(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(i.kernelSize)}.`)}};Conv1D.className="Conv1D",n.m7h.registerClass(Conv1D);let Cropping2D=class Cropping2D extends h.mh{constructor(i){super(i),"number"==typeof i.cropping?this.cropping=[[i.cropping,i.cropping],[i.cropping,i.cropping]]:"number"==typeof i.cropping[0]?this.cropping=[[i.cropping[0],i.cropping[0]],[i.cropping[1],i.cropping[1]]]:this.cropping=i.cropping,this.dataFormat=void 0===i.dataFormat?"channelsLast":i.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(i){return"channelsFirst"===this.dataFormat?[i[0],i[1],i[2]-this.cropping[0][0]-this.cropping[0][1],i[3]-this.cropping[1][0]-this.cropping[1][1]]:[i[0],i[1]-this.cropping[0][0]-this.cropping[0][1],i[2]-this.cropping[1][0]-this.cropping[1][1],i[3]]}call(i,e){return(0,n.lub)(()=>{if(i=(0,f.nQ)(i),"channelsLast"===this.dataFormat){let e=a.uI(i,this.cropping[0][0],i.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return a.uI(e,this.cropping[1][0],i.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{let e=a.uI(i,this.cropping[0][0],i.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return a.uI(e,this.cropping[1][0],i.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){let i={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(i,e),i}};Cropping2D.className="Cropping2D",n.m7h.registerClass(Cropping2D);let UpSampling2D=class UpSampling2D extends h.mh{constructor(i){super(i),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==i.size?this.DEFAULT_SIZE:i.size,this.dataFormat=null==i.dataFormat?"channelsLast":i.dataFormat,(0,l.cj)(this.dataFormat),this.interpolation=null==i.interpolation?"nearest":i.interpolation,(0,l.wU)(this.interpolation)}computeOutputShape(i){if("channelsFirst"===this.dataFormat){let e=null==i[2]?null:this.size[0]*i[2],t=null==i[3]?null:this.size[1]*i[3];return[i[0],i[1],e,t]}{let e=null==i[1]?null:this.size[0]*i[1],t=null==i[2]?null:this.size[1]*i[2];return[i[0],e,t,i[3]]}}call(i,e){return n.lub(()=>{let e=(0,f.nQ)(i),t=e.shape;if("channelsFirst"===this.dataFormat){e=n.p4s(e,[0,2,3,1]);let i=this.size[0]*t[2],s=this.size[1]*t[3],r="nearest"===this.interpolation?n.image.resizeNearestNeighbor(e,[i,s]):n.image.resizeBilinear(e,[i,s]);return n.p4s(r,[0,3,1,2])}{let i=this.size[0]*t[1],s=this.size[1]*t[2];return"nearest"===this.interpolation?n.image.resizeNearestNeighbor(e,[i,s]):n.image.resizeBilinear(e,[i,s])}})}getConfig(){let i={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},e=super.getConfig();return Object.assign(i,e),i}};UpSampling2D.className="UpSampling2D",n.m7h.registerClass(UpSampling2D)}}]);